{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10a438c6-091d-4d48-ab7a-9fb2af81833e",
   "metadata": {},
   "source": [
    "### Check if Everything is Running Correctly  \n",
    "*(number of generations is set to 1 and population to 2)*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88285776-369b-4b73-ae22-5941321b6c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mobilenet_v2\n",
      "Iteration 0 out of 1\n",
      "Starting search\n",
      "Sampling done, took 29.562317609786987  sec\n",
      "[np.float64(1.201688814283319e-07), np.float64(1.0326644520991972e-07), np.float64(1.690243621841217e-08)]\n",
      "Finished 1 eval (1 gen), took 42.299213886260986  sec\n",
      "=================================================================================\n",
      "n_gen  |  n_eval  |     cv_min    |     cv_avg    |     f_avg     |     f_min    \n",
      "=================================================================================\n",
      "     1 |        2 |  8.341397E+01 |  8.861099E+01 |             - |             -\n",
      "time in s: 71.86414647102356\n"
     ]
    }
   ],
   "source": [
    "from CIMNASfun import *\n",
    "# set n_jobs to the number of CPU cores, you want to use\n",
    "n_jobs=61\n",
    "#set to -1 to use all the cores\n",
    "#set to 64 to use 64 cores!\n",
    "dnn_names=[\"mobilenet_v2\"]\n",
    "for dnn_name in dnn_names:\n",
    "    print(dnn_name)\n",
    "    num_generations=1#100\n",
    "    population_size=2#150\n",
    "    # Number of the same experiments to run (set to 1 in most cases)\n",
    "    num_iterations_to_run=1\n",
    "    # Seed if you want to keep randomization controlled for several experiments\n",
    "    seed_alg=1\n",
    "    # Area constraint in cm2:\n",
    "    areaConstrcm2=8\n",
    "    # Objective function type:\n",
    "    typeObj='ela_acc'\n",
    "    # Results folder:\n",
    "    directory = 'resCIMNAS/'+'search_ELA_acc_constr8/'+dnn_name\n",
    "    num_mapping=None\n",
    "    # Set these depending on the experiment and depending on how you want the evolution to go.\n",
    "    prob_cross=0.95 #between 0.0-1.0\n",
    "    eta_cross=3.0 #between 3.0-30.0\n",
    "    prob_mut=0.95 #between 0.0-1.0\n",
    "    eta_mut=3.0 #between 3.0-30.0\n",
    "    run_several_iterations_separate(dnn_name, num_generations, population_size, num_iterations_to_run, seed_alg,areaConstrcm2, typeObj,directory, num_mapping,n_jobs,prob_cross,eta_cross,prob_mut,eta_mut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288a1a97-5198-4954-bd08-c334685d7710",
   "metadata": {},
   "source": [
    "### Next is a more realistic example  \n",
    "*(number of generations = 100, population = 150)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0ffb21-a493-4041-9f02-1bfc39bd2e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from CIMNASfun import *\n",
    "# set n_jobs to the number of CPU cores, you want to use\n",
    "n_jobs=61\n",
    "#set to -1 to use all the cores\n",
    "#set to 64 to use 64 cores!\n",
    "dnn_names=[\"mobilenet_v2\"]\n",
    "for dnn_name in dnn_names:\n",
    "    print(dnn_name)\n",
    "    num_generations=100\n",
    "    population_size=150\n",
    "    # Number of the same experiments to run (set to 1 in most cases)\n",
    "    num_iterations_to_run=1\n",
    "    # Seed if you want to keep randomization controlled for several experiments\n",
    "    seed_alg=1\n",
    "    # Area constraint in cm2:\n",
    "    areaConstrcm2=8\n",
    "    # Objective function type:\n",
    "    typeObj='ela_acc'\n",
    "    # Results folder:\n",
    "    directory = 'resCIMNAS/'+'search_ELA_acc_constr8/'+dnn_name\n",
    "    num_mapping=None\n",
    "    # Set these depending on the experiment and depending on how you want the evolution to go.\n",
    "    prob_cross=0.95 #between 0.0-1.0\n",
    "    eta_cross=3.0 #between 3.0-30.0\n",
    "    prob_mut=0.95 #between 0.0-1.0\n",
    "    eta_mut=3.0 #between 3.0-30.0\n",
    "    run_several_iterations_separate(dnn_name, num_generations, population_size, num_iterations_to_run, seed_alg,areaConstrcm2, typeObj,directory, num_mapping,n_jobs,prob_cross,eta_cross,prob_mut,eta_mut)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb001044-4024-4289-988b-fe58d5453f95",
   "metadata": {},
   "source": [
    "### Example Results and Files\n",
    "\n",
    "- **Example of the results**  \n",
    "  `main/resCIMNAS/example_results_ELA_acc_constr8`\n",
    "\n",
    "- **Search statistics**  \n",
    "  `main/resCIMNAS/example_results_ELA_acc_constr8/mobilenet_v2MeanStat_test0.json`\n",
    "\n",
    "- **Architecture found during the search fitting constraints**  \n",
    "  `main/resCIMNAS/example_results_ELA_acc_constr8/mobilenet_v2/Constrtest0.json`\n",
    "\n",
    "- **All architectures found during the search (fitting and not fitting constraints)**  \n",
    "  `main/resCIMNAS/example_results_ELA_acc_constr8/mobilenet_v2/test0.json`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0476d8-64de-4555-aba3-7989496a52fd",
   "metadata": {},
   "source": [
    "### Displaying the Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8feeabf8-7df9-4aea-b812-225a59b30eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 3 Architectures:\n",
      "*********Top 1 **********\n",
      "This is how the dictionary entry describing the architecture (with hardware and software parameters) looks.\n",
      "A_0.8_8_1e-09_256_32_1_32_64_2048_333342_357333535773535377553_886444864484644864864_886848666446648648684_688444466444488846484_864866884648848464448_3_2_6_0_5_3_1_3_8_3_14_15_18_14_6_13_0_5_33_9_28\n",
      "\n",
      "These are corresponding parameters:\n",
      "Energy (J), area (cm^2), latency (sec), avg_tops_per_mm2, avg_tops_per_w, utilization, area utilized, max_tops_per_mm2, max_tops_per_w, tops, predicted accuracy:\n",
      "{'e': 0.00026779701459567494, 'a': 4.64312239126952, 'l': 1.7020000000000012e-06, 'a_tpm': 13.664785408120636, 'a_tpw': 9.135178400539827, 'u': 0.5787, 'au': 2.686974927827671, 'm_tpm': 41.82123658103854, 'm_tpw': 71.52339100979584, 'tp': 6344.727110033792, 'acc': 0.8809970021247864}\n",
      "\n",
      "Hardware parameters list\n",
      "Voltage, bits_per_cell, base_latency, crossbar_sizeX, crossbar_sizeY, shared_router_groupSize, tiles_in_chip, macros_in_tile, glb_buffer_depth (1024*1024*x*8/2048)):\n",
      "[0.8, 8, 1e-09, 256, 32, 1, 32, 64, 2048]\n",
      "\n",
      "Software parameters:\n",
      "Depth list (number of layers)\n",
      "[3, 3, 3, 3, 4, 2]\n",
      "Kernel size list:\n",
      "[3, 5, 7, 3, 3, 3, 5, 3, 5, 7, 7, 3, 5, 3, 5, 3, 7, 7, 5, 5, 3]\n",
      "Expansion factors list:\n",
      "[5.5, 4.666666666666667, 6.0, 4.0, 5.666666666666667, 4.6, 4.2, 4.6, 5.6, 4.3, 5.4, 5.5, 5.8, 5.166666666666667, 4.5, 5.083333333333333, 4.0, 4.208333333333333, 5.375, 4.375, 5.166666666666667]\n",
      "\n",
      "Quantization parameters (layer-wise):\n",
      "Depthwise convolution weights\n",
      "[6, 8, 8, 4, 4, 4, 4, 6, 6, 4, 4, 4, 4, 8, 8, 8, 4, 6, 4, 8, 4]\n",
      "Pointwise convolution weights\n",
      "[8, 8, 6, 4, 4, 4, 8, 6, 4, 4, 8, 4, 6, 4, 4, 8, 6, 4, 8, 6, 4]\n",
      "Depthwise convolution activation precision\n",
      "[8, 6, 4, 8, 6, 6, 8, 8, 4, 6, 4, 8, 8, 4, 8, 4, 6, 4, 4, 4, 8]\n",
      "Pointwise convolution activation precision\n",
      "[8, 8, 6, 8, 4, 8, 6, 6, 6, 4, 4, 6, 6, 4, 8, 6, 4, 8, 6, 8, 4]\n",
      "\n",
      "*********Top 2 **********\n",
      "This is how the dictionary entry describing the architecture (with hardware and software parameters) looks.\n",
      "A_0.8_8_1e-09_256_32_2_32_32_8192_342224_537573773777535377573_884464846648466886664_486684686688688446484_684844444846486848446_866844484668688484666_3_6_6_5_1_7_1_8_8_5_13_0_0_15_18_20_2_5_32_11_7\n",
      "\n",
      "These are corresponding parameters:\n",
      "Energy (J), area (cm^2), latency (sec), avg_tops_per_mm2, avg_tops_per_w, utilization, area utilized, max_tops_per_mm2, max_tops_per_w, tops, predicted accuracy:\n",
      "{'e': 0.00036094345742744414, 'a': 4.6793764294801194, 'l': 1.5660000000000014e-06, 'a_tpm': 11.705934046799282, 'a_tpw': 4.439989824467598, 'u': 0.5652, 'au': 2.6447835579421635, 'm_tpm': 40.53216980046888, 'm_tpw': 39.50495550161813, 'tp': 5477.64718636414, 'acc': 0.8666199445724487}\n",
      "\n",
      "Hardware parameters list\n",
      "Voltage, bits_per_cell, base_latency, crossbar_sizeX, crossbar_sizeY, shared_router_groupSize, tiles_in_chip, macros_in_tile, glb_buffer_depth (1024*1024*x*8/2048)):\n",
      "[0.8, 8, 1e-09, 256, 32, 2, 32, 32, 8192]\n",
      "\n",
      "Software parameters:\n",
      "Depth list (number of layers)\n",
      "[3, 4, 2, 2, 2, 4]\n",
      "Kernel size list:\n",
      "[5, 3, 7, 5, 7, 3, 7, 7, 3, 7, 7, 7, 5, 3, 5, 3, 7, 7, 5, 7, 3]\n",
      "Expansion factors list:\n",
      "[5.5, 6.0, 6.0, 5.666666666666667, 4.333333333333333, 5.4, 4.2, 5.6, 5.6, 4.5, 5.3, 4.0, 4.0, 5.25, 5.5, 5.666666666666667, 4.166666666666667, 4.208333333333333, 5.333333333333333, 4.458333333333333, 4.291666666666667]\n",
      "\n",
      "Quantization parameters (layer-wise):\n",
      "Depthwise convolution weights\n",
      "[6, 8, 4, 8, 4, 4, 4, 4, 4, 8, 4, 6, 4, 8, 6, 8, 4, 8, 4, 4, 6]\n",
      "Pointwise convolution weights\n",
      "[8, 8, 4, 4, 6, 4, 8, 4, 6, 6, 4, 8, 4, 6, 6, 8, 8, 6, 6, 6, 4]\n",
      "Depthwise convolution activation precision\n",
      "[8, 6, 6, 8, 4, 4, 4, 8, 4, 6, 6, 8, 6, 8, 8, 4, 8, 4, 6, 6, 6]\n",
      "Pointwise convolution activation precision\n",
      "[4, 8, 6, 6, 8, 4, 6, 8, 6, 6, 8, 8, 6, 8, 8, 4, 4, 6, 4, 8, 4]\n",
      "\n",
      "*********Top 3 **********\n",
      "This is how the dictionary entry describing the architecture (with hardware and software parameters) looks.\n",
      "A_0.5_3_1e-09_512_32_2_8_64_2048_244433_335733735353555735553_646844646484686664684_484888668888684468888_888484866848444444484_684486664846486648684_3_1_3_0_3_8_4_8_8_14_18_16_4_20_24_20_7_32_19_23_24\n",
      "\n",
      "These are corresponding parameters:\n",
      "Energy (J), area (cm^2), latency (sec), avg_tops_per_mm2, avg_tops_per_w, utilization, area utilized, max_tops_per_mm2, max_tops_per_w, tops, predicted accuracy:\n",
      "{'e': 0.00032862269780729766, 'a': 2.34429218874792, 'l': 3.5580000000000018e-06, 'a_tpm': 9.081509729077771, 'a_tpw': 6.602525252630049, 'u': 0.5981000000000001, 'au': 1.402121158090131, 'm_tpm': 35.315734274667406, 'm_tpw': 52.8550165753332, 'tp': 2128.9712319915247, 'acc': 0.8822014927864075}\n",
      "\n",
      "Hardware parameters list\n",
      "Voltage, bits_per_cell, base_latency, crossbar_sizeX, crossbar_sizeY, shared_router_groupSize, tiles_in_chip, macros_in_tile, glb_buffer_depth (1024*1024*x*8/2048)):\n",
      "[0.5, 3, 1e-09, 512, 32, 2, 8, 64, 2048]\n",
      "\n",
      "Software parameters:\n",
      "Depth list (number of layers)\n",
      "[2, 4, 4, 4, 3, 3]\n",
      "Kernel size list:\n",
      "[3, 3, 5, 7, 3, 3, 7, 3, 5, 3, 5, 3, 5, 5, 5, 7, 3, 5, 5, 5, 3]\n",
      "Expansion factors list:\n",
      "[5.5, 4.333333333333333, 5.0, 4.0, 5.0, 5.6, 4.8, 5.6, 5.6, 5.4, 5.8, 5.6, 4.4, 5.666666666666667, 6.0, 5.666666666666667, 4.583333333333333, 5.333333333333333, 4.791666666666667, 4.958333333333333, 5.0]\n",
      "\n",
      "Quantization parameters (layer-wise):\n",
      "Depthwise convolution weights\n",
      "[8, 8, 8, 4, 8, 4, 8, 6, 6, 8, 4, 8, 4, 4, 4, 4, 4, 4, 4, 8, 4]\n",
      "Pointwise convolution weights\n",
      "[6, 4, 6, 8, 4, 4, 6, 4, 6, 4, 8, 4, 6, 8, 6, 6, 6, 4, 6, 8, 4]\n",
      "Depthwise convolution activation precision\n",
      "[6, 8, 4, 4, 8, 6, 6, 6, 4, 8, 4, 6, 4, 8, 6, 6, 4, 8, 6, 8, 4]\n",
      "Pointwise convolution activation precision\n",
      "[4, 8, 4, 8, 8, 8, 6, 6, 8, 8, 8, 8, 6, 8, 4, 4, 6, 8, 8, 8, 8]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from scripts_new import *\n",
    "path='resCIMNAS/example_results_ELA_acc_constr8/mobilenet_v2/Constrtest0.json'\n",
    "data={}\n",
    "data=load_dict_from_json(path)\n",
    "keys_list = list(data.keys())\n",
    "scores={}\n",
    "coeff_lat, coeff_en, coeff_ar, coeff_acc=1.0,1.0,1.0,1.0\n",
    "typeObj='ela_acc'\n",
    "for keys in keys_list:\n",
    "    latency=data[keys]['l']\n",
    "    energy=data[keys]['e']\n",
    "    area=data[keys]['a']\n",
    "    accuracy=data[keys]['acc']\n",
    "    scores[keys]=objective(latency, energy, area, accuracy, coeff_lat, coeff_en, coeff_ar, coeff_acc, typeObj)\n",
    "    \n",
    "top_10 = sorted(scores.items(), key=lambda x: x[1], reverse=False)[:10]\n",
    "\n",
    "# plotting top architectures based on the objective function\n",
    "print('Top 3 Architectures:')\n",
    "topx=0\n",
    "for dicts in top_10[:3]:\n",
    "    print('*********Top', topx+1,'**********')\n",
    "    print('This is how the dictionary entry describing the architecture (with hardware and software parameters) looks.')\n",
    "    print(dicts[0])\n",
    "    print('')\n",
    "    print('These are corresponding parameters:')\n",
    "    print('Energy (J), area (cm^2), latency (sec), avg_tops_per_mm2, avg_tops_per_w, utilization, area utilized, max_tops_per_mm2, max_tops_per_w, tops, predicted accuracy:')\n",
    "    print(data[dicts[0]])\n",
    "    print('')\n",
    "    hardware_number_list, d_list, ks_list, e_list, pw_w_bits_list, pw_a_bits_list, dw_w_bits_list, dw_a_bits_list,e_list_index=get_dictCIMNAS(dicts[0])\n",
    "    print('Hardware parameters list') \n",
    "    print('Voltage, bits_per_cell, base_latency, crossbar_sizeX, crossbar_sizeY, shared_router_groupSize, tiles_in_chip, macros_in_tile, glb_buffer_depth (1024*1024*x*8/2048)):')\n",
    "    print(hardware_number_list)\n",
    "    print('')\n",
    "    print('Software parameters:')\n",
    "    print('Depth list (number of layers)')\n",
    "    print(d_list)\n",
    "    print('Kernel size list:')\n",
    "    print(ks_list)\n",
    "    print('Expansion factors list:')\n",
    "    print(e_list)\n",
    "    print('')\n",
    "    print('Quantization parameters (layer-wise):')\n",
    "    print('Depthwise convolution weights')\n",
    "    print(dw_w_bits_list)\n",
    "    print('Pointwise convolution weights')\n",
    "    print(pw_w_bits_list)\n",
    "    print('Depthwise convolution activation precision')\n",
    "    print(dw_a_bits_list)\n",
    "    print('Pointwise convolution activation precision')\n",
    "    print(pw_a_bits_list)\n",
    "    print('')\n",
    "\n",
    "    topx=topx+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4fdb0-b529-4508-a3a1-a08614f02e8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce558f9-e83d-4c43-a24c-2368f1550c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
